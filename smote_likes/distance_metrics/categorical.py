import numpy
from sklearn.metrics import euclidean_distances

from .helpers import ShapeError, _get_cond_proba, _remap_ndarray_dict


def normalized_vdm_2(X: numpy.ndarray, y: numpy.ndarray):
    r"""Computes Normalised Value Difference Metric 2

    Parameters
    ----------
    X : numpy.ndarray
        Feature matrix with dimensions (observations, features).
    y : numpy.ndarray
        Target class for each row in X.

    Returns
    -------
    numpy.ndarray
        A distance array of size (observations, observations) with all
        pairwise distances between observations. See notes for returned
        value.

    Notes
    -----
    The distance matrix returned corresponds to 

    .. math::

        normalized\_vdm(x, y) \\
        &= \sum_{b=1}^{cat} normalized\_vdm_b(x, y) \\
        &= \sum_{b=1}^{cat} \sum_{c=1}^{C} \left | P_{b,x,c} - P_{b,y,c} \right | ^2 \\
        &= \sum_{b=1}^{cat} \sum_{c=1}^{C} \left | \frac {N_{b,x,c}} {N_{b,x}} - \frac {N_{b,y,c}} {N_{b,y}}   \right | ^2

    where C is the list of classes and cat is the list of 
    categorical attributes. Corresponds to 
    :math:`\sum_{b=1}^{cat} d_{b}^2(x, y)` 
    from :py:func:`smote_likes.distance_metrics.hvdm`.

    Based on normalized_vdm2 (Equation 15) from :cite:t:`Wilson1997`. 
    As per the paper the square root is not taken, because the individual 
    attribute distances are themselves squared when applied in the HVDM function.

    Note1: The algorithm expects that all attributes of X are categorical features
    encoded as numeric.

    Note2: The returned distance matrix can be summed element-wise 
    with the distance matrices generated by other types of attributes.

    Note3: To calculate pairwise distance between observations see
    :py:func:`smote_likes.distance_metrics.nvdm2`.

    """

    cond_proba_list = get_cond_probas(X=X, y=y)
    unique_targets = numpy.unique(y)

    list_pdist_per_class = []
    for trgt in unique_targets:
        all_cols = []
        for col in range(X.shape[1]):
            # return the conditional probabilties from the dictionary
            # corresponding to each value in the column
            P_ac = _remap_ndarray_dict(X[:, col], cond_proba_list[col][trgt])
            P_ac = P_ac.reshape(X.shape[0], 1)
            all_cols.append(P_ac)
        # X_P_c is the matrix of categorical features
        # but each is replaced with the conditional
        # probability of the corresponding class
        # and has shape (observations, attributes)
        X_P_c = numpy.hstack(all_cols)
        if not X.shape == X_P_c.shape:
            raise ShapeError("Internal transformation led to object malformation. \
                Original shape: {}, current shape: {}".format(X.shape, X_P_c.shape))
        #  squared euclidean distance
        pdist_c = euclidean_distances(X=X_P_c, squared=True)
        list_pdist_per_class.append(pdist_c)

    return sum(list_pdist_per_class)


def nvdm2(X: numpy.ndarray, Y: numpy.ndarray, cond_proba_list: list, idist: bool = True) -> list:
    r""" Calculate the nvdm2 between two observations 
    :math:`\sum_{c=1}^{C} \left | P_{x,c} - P_{y,c} \right |^2`
    for c classes accross all attributes.

    Parameters
    ----------
    X : numpy.ndarray
        The row-vector with all attributes of one observation
    Y : numpy.ndarray
        The row-vector with all attributes of another observation
    cond_proba_list : list of dict
        List of dicts of conditional probabilities as generated by
        :py:func:`smote_likes.distance_metrics.get_cond_probas`.
    idist : bool, optional
        If False returns the sum of all distances, if True the 
        individual distances between attributes. By default True.

    Returns
    -------
    list
        The individual distances between any two attributes of the observations.

    Notes
    -----
    The algorithm expects that all attributes of X are categorical features
    encoded as numeric.
    """
    dist_list = []
    for a, b, cond_pr_dict in zip(X, Y, cond_proba_list):
        d = 0
        for trgt in cond_pr_dict.keys():
            d += numpy.square(cond_pr_dict[trgt][a] - cond_pr_dict[trgt][b])
        dist_list.append(d)
    if not idist:
        dist_list = numpy.sum(dist_list)
    return dist_list


def get_cond_probas(X: numpy.ndarray, y: numpy.ndarray) -> list:
    """Get a list of all conditional probabilities in each column of X

    Parameters
    ----------
    X : numpy.ndarray
        Feature matrix with dimensions (observations, features).
    y : numpy.ndarray
        y class for each row in X.

    Returns
    -------
    list
        Each entry contains the conditional probability :math:`P_{a,x,c}` 
        in a dictionary with following structure:

        `target value -> attribute value -> attribute count`
    """
    cond_proba_list = []
    if len(X.shape) != 2:
        raise ValueError("Shape of X needs to be 2 dimensional")
    for cat_ind in range(X.shape[1]):
        cond_proba_list.append(_get_cond_proba(X[:, cat_ind], y))

    return cond_proba_list
